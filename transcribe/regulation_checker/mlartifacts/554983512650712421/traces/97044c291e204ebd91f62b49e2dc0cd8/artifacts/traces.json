{"spans": [{"trace_id": "yHRvTpkmri8eIfgbBdTbdw==", "span_id": "19JHUgZp6e8=", "trace_state": "", "parent_span_id": "", "name": "Crew.kickoff", "start_time_unix_nano": 1753087328059598400, "end_time_unix_nano": 1753087328265966600, "attributes": {"process": "\"hierarchical\"", "tasks": "\"[{'agent': 'Compliance Manager', 'description': 'Manage the process of analyzing a transcript segment for compliance violations. First, delegate the analysis of the segment: \\\"{transcript_segment}\\\" to the compliance_analyst. Then, delegate the creation of a final report to the compliance_reporter based on the analysis. Finally, review the report for accuracy and completeness before finishing the task.\\\\n', 'async_execution': False, 'expected_output': 'The final, verified compliance report.\\\\n', 'human_input': False, 'tools': [], 'output_file': None}, {'agent': 'Compliance Analyst', 'description': 'Analyze the following transcript segment for any potential compliance violations based on the provided knowledge base: {transcript_segment}. Focus on identifying specific phrases or statements that might indicate a breach of policy or regulation.\\\\n', 'async_execution': False, 'expected_output': 'A list of potential compliance violations found in the text, with a brief explanation for each. If no violations are found, state that clearly.\\\\n', 'human_input': False, 'tools': [JSONSearchTool(name=\\\"Search a JSON's content\\\", description='Tool Name: Search a JSON\\\\'s content\\\\nTool Arguments: {\\\\'search_query\\\\': {\\\\'description\\\\': \\\"Mandatory search query you want to use to search the JSON\\\\'s content\\\", \\\\'type\\\\': \\\\'str\\\\'}}\\\\nTool Description: A tool that can be used to semantic search a query the \\\\\\\\data.json JSON\\\\'s content.', env_vars=[], args_schema=<class 'crewai_tools.tools.json_search_tool.json_search_tool.FixedJSONSearchToolSchema'>, description_updated=False, cache_function=<function BaseTool.<lambda> at 0x000001C8AFC30680>, result_as_answer=False, max_usage_count=None, current_usage_count=0, summarize=False, adapter=EmbedchainAdapter(embedchain_app=<embedchain.app.App object at 0x000001C8C23DC5D0>, summarize=False), config={'llm': {'provider': 'google', 'config': {'model': 'gemini-pro'}}, 'embedding_model': {'provider': 'google', 'config': {'model': 'models/embedding-001', 'task_type': 'retrieval_document'}}})], 'output_file': None}, {'agent': 'Compliance Reporter', 'description': 'Review the analysis of the transcript segment and create a comprehensive compliance report. The report should summarize the findings, detail any violations, and suggest a risk level.\\\\n', 'async_execution': False, 'expected_output': 'A well-structured compliance report in markdown format. It should include an executive summary, a list of findings, and a final compliance assessment.\\\\n', 'human_input': False, 'tools': [JSONSearchTool(name=\\\"Search a JSON's content\\\", description='Tool Name: Search a JSON\\\\'s content\\\\nTool Arguments: {\\\\'search_query\\\\': {\\\\'description\\\\': \\\"Mandatory search query you want to use to search the JSON\\\\'s content\\\", \\\\'type\\\\': \\\\'str\\\\'}}\\\\nTool Description: A tool that can be used to semantic search a query the \\\\\\\\data.json JSON\\\\'s content.', env_vars=[], args_schema=<class 'crewai_tools.tools.json_search_tool.json_search_tool.FixedJSONSearchToolSchema'>, description_updated=False, cache_function=<function BaseTool.<lambda> at 0x000001C8AFC30680>, result_as_answer=False, max_usage_count=None, current_usage_count=0, summarize=False, adapter=EmbedchainAdapter(embedchain_app=<embedchain.app.App object at 0x000001C8C23DC5D0>, summarize=False), config={'llm': {'provider': 'google', 'config': {'model': 'gemini-pro'}}, 'embedding_model': {'provider': 'google', 'config': {'model': 'models/embedding-001', 'task_type': 'retrieval_document'}}})], 'output_file': None}]\"", "manager_llm": "{\"name\": null, \"disable_streaming\": false, \"model\": \"models/gemini-pro\", \"google_api_key\": \"**********\", \"credentials\": null, \"temperature\": 0.7, \"top_p\": null, \"top_k\": null, \"max_output_tokens\": null, \"n\": 1, \"max_retries\": 6, \"timeout\": null, \"client_options\": null, \"transport\": null, \"additional_headers\": null, \"response_modalities\": null, \"thinking_budget\": null, \"include_thoughts\": null, \"safety_settings\": null, \"default_metadata\": [], \"convert_system_message_to_human\": false, \"response_mime_type\": null, \"response_schema\": null, \"cached_content\": null, \"model_kwargs\": {}}", "share_crew": "false", "id": "\"dea95942-8c1c-435b-8648-6492c96c4128\"", "cache": "true", "verbose": "true", "execution_logs": "\"[]\"", "planning": "false", "security_config": "{\"version\": \"1.0.0\", \"fingerprint\": {\"uuid_str\": \"cd53c3a3-9bc1-41eb-b6f8-63cf2d6a8b47\", \"created_at\": \"2025-07-21 11:42:07.719805\", \"metadata\": {}}}", "before_kickoff_callbacks": "\"[]\"", "mlflow.traceRequestId": "\"97044c291e204ebd91f62b49e2dc0cd8\"", "after_kickoff_callbacks": "\"[<function crew.<locals>.wrapper.<locals>.callback_wrapper.<locals>.wrapper at 0x000001C8C2258220>]\"", "mlflow.spanType": "\"CHAIN\"", "mlflow.spanInputs": "{\"inputs\": {\"transcript_segment\": \"انا عرضت data العملاء علي اخويا وهو قالي كدا\"}}", "memory": "false", "agents": "\"[{'id': '0a0cce4a-3bfc-4c52-b302-232390f2c0cd', 'role': 'Compliance Manager', 'goal': 'Oversee the compliance analysis and reporting process. Ensure the final report is accurate, complete, and addresses all potential risks identified in the transcript segment by delegating tasks to the analyst and reporter.\\\\n', 'backstory': 'You are an experienced compliance manager with a keen eye for detail and a talent for coordinating team efforts. Your primary responsibility is to ensure that all compliance checks are thorough and that the final reports are clear, concise, and actionable.\\\\n', 'cache': True, 'config': None, 'verbose': True, 'allow_delegation': False, 'tools': [], 'max_iter': 25, 'llm': 'gemini/gemini-2.0-flash'}, {'id': '0e496640-e414-4480-8c41-97c62505fe4f', 'role': 'Compliance Analyst', 'goal': 'Perform comprehensive compliance analysis of input phrases using intelligent screening.\\\\nPHASE 1 - PRELIMINARY JUDGMENT: Use your expertise to quickly assess if the phrase is: - Obviously safe routine business communication (greetings, project updates, scheduling) - Clearly irrelevant to compliance concerns - Standard workplace conversation with no red flags\\\\nIf obviously safe, immediately respond with \\\"SAFE - No compliance concerns detected\\\" and provide brief reasoning.\\\\nPHASE 2 - DETAILED ANALYSIS: Only if the phrase contains potential risks, ambiguous content, or compliance-relevant keywords: - Search the knowledge base (data.json) for specific regulatory matches - Apply built-in compliance intelligence for violation detection - Analyze against regulatory frameworks (SEC, GDPR, FCPA, SOX, OSHA, etc.) - Evaluate policy violations and risk factors\\\\nIf knowledge base search yields no results, apply your expertise to determine if genuine violations exist. Provide detailed analysis findings including violation types, regulatory frameworks, risk levels, and evidence.\\\\n', 'backstory': 'You are a senior compliance analyst with deep expertise in regulatory frameworks, corporate policies,  and violation detection. You excel at quickly distinguishing between routine business communication  and genuine compliance risks. You rely on documented knowledge when available, but can apply your  extensive experience when knowledge bases are incomplete. You prioritize accuracy over false alarms  and provide thorough analysis only when warranted.\\\\n', 'cache': True, 'config': None, 'verbose': True, 'allow_delegation': False, 'tools': [JSONSearchTool(name=\\\"Search a JSON's content\\\", description='Tool Name: Search a JSON\\\\'s content\\\\nTool Arguments: {\\\\'search_query\\\\': {\\\\'description\\\\': \\\"Mandatory search query you want to use to search the JSON\\\\'s content\\\", \\\\'type\\\\': \\\\'str\\\\'}}\\\\nTool Description: A tool that can be used to semantic search a query the \\\\\\\\data.json JSON\\\\'s content.', env_vars=[], args_schema=<class 'crewai_tools.tools.json_search_tool.json_search_tool.FixedJSONSearchToolSchema'>, description_updated=False, cache_function=<function BaseTool.<lambda> at 0x000001C8AFC30680>, result_as_answer=False, max_usage_count=None, current_usage_count=0, summarize=False, adapter=EmbedchainAdapter(embedchain_app=<embedchain.app.App object at 0x000001C8C23DC5D0>, summarize=False), config={'llm': {'provider': 'google', 'config': {'model': 'gemini-pro'}}, 'embedding_model': {'provider': 'google', 'config': {'model': 'models/embedding-001', 'task_type': 'retrieval_document'}}})], 'max_iter': 25, 'llm': 'gemini/gemini-2.0-flash'}, {'id': '82477b87-c808-4de7-a13a-6c69a8ef8a3b', 'role': 'Compliance Reporter', 'goal': \\\"Generate executive-level compliance reports based on the compliance_analyst's findings.\\\\nCreate final compliance determinations with clear, actionable guidance:\\\\nFOR SAFE DETERMINATIONS: - Confirm the safety classification with confidence level - Document the analysis method used (preliminary screening vs. full analysis) - Provide brief executive summary - Set appropriate monitoring level (routine/standard)\\\\nFOR VIOLATION DETERMINATIONS: - Detail specific compliance violations and regulatory concerns - List applicable regulatory frameworks and policy breaches - Classify risk severity and urgency level - Outline required immediate actions and escalation procedures - Specify responsible parties and follow-up requirements - Determine alert level and notification protocols\\\\nAlways provide clear final verdicts: SAFE or VIOLATION Include confidence levels, risk classifications, and actionable next steps. Ensure executives can make informed decisions based on your reports.\\\\n\\\", 'backstory': 'You are an experienced compliance reporting specialist who translates technical compliance  analysis into clear, actionable executive guidance. You excel at synthesizing complex  regulatory findings into concise reports that enable quick decision-making. You understand  business impact, escalation requirements, and risk management. Your reports are trusted  by senior management for their accuracy, clarity, and practical recommendations. You ensure  appropriate responses to both genuine violations and false alarms.\\\\n', 'cache': True, 'config': None, 'verbose': True, 'allow_delegation': True, 'tools': [JSONSearchTool(name=\\\"Search a JSON's content\\\", description='Tool Name: Search a JSON\\\\'s content\\\\nTool Arguments: {\\\\'search_query\\\\': {\\\\'description\\\\': \\\"Mandatory search query you want to use to search the JSON\\\\'s content\\\", \\\\'type\\\\': \\\\'str\\\\'}}\\\\nTool Description: A tool that can be used to semantic search a query the \\\\\\\\data.json JSON\\\\'s content.', env_vars=[], args_schema=<class 'crewai_tools.tools.json_search_tool.json_search_tool.FixedJSONSearchToolSchema'>, description_updated=False, cache_function=<function BaseTool.<lambda> at 0x000001C8AFC30680>, result_as_answer=False, max_usage_count=None, current_usage_count=0, summarize=False, adapter=EmbedchainAdapter(embedchain_app=<embedchain.app.App object at 0x000001C8C23DC5D0>, summarize=False), config={'llm': {'provider': 'google', 'config': {'model': 'gemini-pro'}}, 'embedding_model': {'provider': 'google', 'config': {'model': 'models/embedding-001', 'task_type': 'retrieval_document'}}})], 'max_iter': 25, 'llm': 'gemini/gemini-2.0-flash'}]\""}, "events": [{"time_unix_nano": 1753087328264953800, "name": "exception", "attributes": {"exception.type": "litellm.exceptions.BadRequestError", "exception.message": "litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=models/gemini-pro\n Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers", "exception.stacktrace": "Traceback (most recent call last):\n  File \"C:\\Users\\amros\\.conda\\envs\\whisper_test\\Lib\\site-packages\\opentelemetry\\trace\\__init__.py\", line 589, in use_span\n    yield span\n  File \"C:\\Users\\amros\\.conda\\envs\\whisper_test\\Lib\\site-packages\\mlflow\\tracing\\fluent.py\", line 478, in start_span\n    yield mlflow_span\n  File \"C:\\Users\\amros\\.conda\\envs\\whisper_test\\Lib\\site-packages\\mlflow\\crewai\\autolog.py\", line 28, in patched_class_call\n    result = original(self, *args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\amros\\.conda\\envs\\whisper_test\\Lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py\", line 475, in call_original\n    return call_original_fn_with_event_logging(_original_fn, og_args, og_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\amros\\.conda\\envs\\whisper_test\\Lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py\", line 426, in call_original_fn_with_event_logging\n    original_fn_result = original_fn(*og_args, **og_kwargs)\n                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\amros\\.conda\\envs\\whisper_test\\Lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py\", line 472, in _original_fn\n    original_result = original(*_og_args, **_og_kwargs)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\amros\\.conda\\envs\\whisper_test\\Lib\\site-packages\\crewai\\crew.py\", line 671, in kickoff\n    result = self._run_hierarchical_process()\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\amros\\.conda\\envs\\whisper_test\\Lib\\site-packages\\crewai\\crew.py\", line 785, in _run_hierarchical_process\n    return self._execute_tasks(self.tasks)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\amros\\.conda\\envs\\whisper_test\\Lib\\site-packages\\crewai\\crew.py\", line 883, in _execute_tasks\n    task_output = task.execute_sync(\n                  ^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\amros\\.conda\\envs\\whisper_test\\Lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py\", line 484, in safe_patch_function\n    patch_function(call_original, *args, **kwargs)\n  File \"C:\\Users\\amros\\.conda\\envs\\whisper_test\\Lib\\site-packages\\mlflow\\crewai\\autolog.py\", line 28, in patched_class_call\n    result = original(self, *args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\amros\\.conda\\envs\\whisper_test\\Lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py\", line 475, in call_original\n    return call_original_fn_with_event_logging(_original_fn, og_args, og_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\amros\\.conda\\envs\\whisper_test\\Lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py\", line 426, in call_original_fn_with_event_logging\n    original_fn_result = original_fn(*og_args, **og_kwargs)\n                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\amros\\.conda\\envs\\whisper_test\\Lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py\", line 472, in _original_fn\n    original_result = original(*_og_args, **_og_kwargs)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\amros\\.conda\\envs\\whisper_test\\Lib\\site-packages\\crewai\\task.py\", line 356, in execute_sync\n    return self._execute_core(agent, context, tools)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\amros\\.conda\\envs\\whisper_test\\Lib\\site-packages\\crewai\\task.py\", line 504, in _execute_core\n    raise e  # Re-raise the exception after emitting the event\n    ^^^^^^^\n  File \"C:\\Users\\amros\\.conda\\envs\\whisper_test\\Lib\\site-packages\\crewai\\task.py\", line 420, in _execute_core\n    result = agent.execute_task(\n             ^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\amros\\.conda\\envs\\whisper_test\\Lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py\", line 484, in safe_patch_function\n    patch_function(call_original, *args, **kwargs)\n  File \"C:\\Users\\amros\\.conda\\envs\\whisper_test\\Lib\\site-packages\\mlflow\\crewai\\autolog.py\", line 28, in patched_class_call\n    result = original(self, *args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\amros\\.conda\\envs\\whisper_test\\Lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py\", line 475, in call_original\n    return call_original_fn_with_event_logging(_original_fn, og_args, og_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\amros\\.conda\\envs\\whisper_test\\Lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py\", line 426, in call_original_fn_with_event_logging\n    original_fn_result = original_fn(*og_args, **og_kwargs)\n                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\amros\\.conda\\envs\\whisper_test\\Lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py\", line 472, in _original_fn\n    original_result = original(*_og_args, **_og_kwargs)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\amros\\.conda\\envs\\whisper_test\\Lib\\site-packages\\crewai\\agent.py\", line 462, in execute_task\n    raise e\n  File \"C:\\Users\\amros\\.conda\\envs\\whisper_test\\Lib\\site-packages\\crewai\\agent.py\", line 438, in execute_task\n    result = self._execute_without_timeout(task_prompt, task)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\amros\\.conda\\envs\\whisper_test\\Lib\\site-packages\\crewai\\agent.py\", line 534, in _execute_without_timeout\n    return self.agent_executor.invoke(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\amros\\.conda\\envs\\whisper_test\\Lib\\site-packages\\crewai\\agents\\crew_agent_executor.py\", line 125, in invoke\n    raise e\n  File \"C:\\Users\\amros\\.conda\\envs\\whisper_test\\Lib\\site-packages\\crewai\\agents\\crew_agent_executor.py\", line 114, in invoke\n    formatted_answer = self._invoke_loop()\n                       ^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\amros\\.conda\\envs\\whisper_test\\Lib\\site-packages\\crewai\\agents\\crew_agent_executor.py\", line 211, in _invoke_loop\n    raise e\n  File \"C:\\Users\\amros\\.conda\\envs\\whisper_test\\Lib\\site-packages\\crewai\\agents\\crew_agent_executor.py\", line 157, in _invoke_loop\n    answer = get_llm_response(\n             ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\amros\\.conda\\envs\\whisper_test\\Lib\\site-packages\\crewai\\utilities\\agent_utils.py\", line 164, in get_llm_response\n    raise e\n  File \"C:\\Users\\amros\\.conda\\envs\\whisper_test\\Lib\\site-packages\\crewai\\utilities\\agent_utils.py\", line 153, in get_llm_response\n    answer = llm.call(\n             ^^^^^^^^^\n  File \"C:\\Users\\amros\\.conda\\envs\\whisper_test\\Lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py\", line 484, in safe_patch_function\n    patch_function(call_original, *args, **kwargs)\n  File \"C:\\Users\\amros\\.conda\\envs\\whisper_test\\Lib\\site-packages\\mlflow\\crewai\\autolog.py\", line 28, in patched_class_call\n    result = original(self, *args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\amros\\.conda\\envs\\whisper_test\\Lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py\", line 475, in call_original\n    return call_original_fn_with_event_logging(_original_fn, og_args, og_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\amros\\.conda\\envs\\whisper_test\\Lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py\", line 426, in call_original_fn_with_event_logging\n    original_fn_result = original_fn(*og_args, **og_kwargs)\n                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\amros\\.conda\\envs\\whisper_test\\Lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py\", line 472, in _original_fn\n    original_result = original(*_og_args, **_og_kwargs)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\amros\\.conda\\envs\\whisper_test\\Lib\\site-packages\\crewai\\llm.py\", line 977, in call\n    return self._handle_non_streaming_response(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\amros\\.conda\\envs\\whisper_test\\Lib\\site-packages\\crewai\\llm.py\", line 782, in _handle_non_streaming_response\n    response = litellm.completion(**params)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\amros\\.conda\\envs\\whisper_test\\Lib\\site-packages\\litellm\\utils.py\", line 1285, in wrapper\n    raise e\n  File \"C:\\Users\\amros\\.conda\\envs\\whisper_test\\Lib\\site-packages\\litellm\\utils.py\", line 1163, in wrapper\n    result = original_function(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\amros\\.conda\\envs\\whisper_test\\Lib\\site-packages\\litellm\\main.py\", line 3304, in completion\n    raise exception_type(\n  File \"C:\\Users\\amros\\.conda\\envs\\whisper_test\\Lib\\site-packages\\litellm\\main.py\", line 1052, in completion\n    model, custom_llm_provider, dynamic_api_key, api_base = get_llm_provider(\n                                                            ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\amros\\.conda\\envs\\whisper_test\\Lib\\site-packages\\litellm\\litellm_core_utils\\get_llm_provider_logic.py\", line 373, in get_llm_provider\n    raise e\n  File \"C:\\Users\\amros\\.conda\\envs\\whisper_test\\Lib\\site-packages\\litellm\\litellm_core_utils\\get_llm_provider_logic.py\", line 350, in get_llm_provider\n    raise litellm.exceptions.BadRequestError(  # type: ignore\nlitellm.exceptions.BadRequestError: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=models/gemini-pro\n Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers\n", "exception.escaped": "False"}}], "status": {"message": "BadRequestError: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=models/gemini-pro\n Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers", "code": "STATUS_CODE_ERROR"}}, {"trace_id": "yHRvTpkmri8eIfgbBdTbdw==", "span_id": "4mWmhjwyZXk=", "trace_state": "", "parent_span_id": "19JHUgZp6e8=", "name": "Task.execute_sync", "start_time_unix_nano": 1753087328093422100, "end_time_unix_nano": 1753087328253471700, "attributes": {"description": "\"Manage the process of analyzing a transcript segment for compliance violations. First, delegate the analysis of the segment: \\\"انا عرضت data العملاء علي اخويا وهو قالي كدا\\\" to the compliance_analyst. Then, delegate the creation of a final report to the compliance_reporter based on the analysis. Finally, review the report for accuracy and completeness before finishing the task.\\n\"", "context": "\"NOT_SPECIFIED\"", "id": "\"9c512fa2-26c7-4340-a0d3-aea8fa6c5304\"", "human_input": "\"False\"", "delegations": "\"0\"", "tools_errors": "\"0\"", "create_directory": "\"True\"", "async_execution": "\"False\"", "agent": "\"Compliance Manager\"", "name": "\"overall_compliance_review_task\"", "tools": "\"[]\"", "security_config": "\"version='1.0.0' fingerprint=Fingerprint(uuid_str='97b4f06c-6793-43db-94aa-b51e8b50332b', created_at=datetime.datetime(2025, 7, 21, 11, 42, 7, 703406), metadata={})\"", "mlflow.traceRequestId": "\"97044c291e204ebd91f62b49e2dc0cd8\"", "processed_by_agents": "\"set()\"", "markdown": "\"False\"", "mlflow.spanType": "\"CHAIN\"", "mlflow.spanInputs": "{\"context\": \"\"}", "expected_output": "\"The final, verified compliance report.\\n\"", "max_retries": "\"3\"", "i18n": "\"prompt_file=None\"", "used_tools": "\"0\"", "retry_count": "\"0\""}, "events": [{"time_unix_nano": 1753087328253471700, "name": "exception", "attributes": {"exception.type": "litellm.exceptions.BadRequestError", "exception.message": "litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=models/gemini-pro\n Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers", "exception.stacktrace": "Traceback (most recent call last):\n  File \"C:\\Users\\amros\\.conda\\envs\\whisper_test\\Lib\\site-packages\\opentelemetry\\trace\\__init__.py\", line 589, in use_span\n    yield span\n  File \"C:\\Users\\amros\\.conda\\envs\\whisper_test\\Lib\\site-packages\\mlflow\\tracing\\fluent.py\", line 478, in start_span\n    yield mlflow_span\n  File \"C:\\Users\\amros\\.conda\\envs\\whisper_test\\Lib\\site-packages\\mlflow\\crewai\\autolog.py\", line 28, in patched_class_call\n    result = original(self, *args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\amros\\.conda\\envs\\whisper_test\\Lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py\", line 475, in call_original\n    return call_original_fn_with_event_logging(_original_fn, og_args, og_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\amros\\.conda\\envs\\whisper_test\\Lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py\", line 426, in call_original_fn_with_event_logging\n    original_fn_result = original_fn(*og_args, **og_kwargs)\n                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\amros\\.conda\\envs\\whisper_test\\Lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py\", line 472, in _original_fn\n    original_result = original(*_og_args, **_og_kwargs)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\amros\\.conda\\envs\\whisper_test\\Lib\\site-packages\\crewai\\task.py\", line 356, in execute_sync\n    return self._execute_core(agent, context, tools)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\amros\\.conda\\envs\\whisper_test\\Lib\\site-packages\\crewai\\task.py\", line 504, in _execute_core\n    raise e  # Re-raise the exception after emitting the event\n    ^^^^^^^\n  File \"C:\\Users\\amros\\.conda\\envs\\whisper_test\\Lib\\site-packages\\crewai\\task.py\", line 420, in _execute_core\n    result = agent.execute_task(\n             ^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\amros\\.conda\\envs\\whisper_test\\Lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py\", line 484, in safe_patch_function\n    patch_function(call_original, *args, **kwargs)\n  File \"C:\\Users\\amros\\.conda\\envs\\whisper_test\\Lib\\site-packages\\mlflow\\crewai\\autolog.py\", line 28, in patched_class_call\n    result = original(self, *args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\amros\\.conda\\envs\\whisper_test\\Lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py\", line 475, in call_original\n    return call_original_fn_with_event_logging(_original_fn, og_args, og_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\amros\\.conda\\envs\\whisper_test\\Lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py\", line 426, in call_original_fn_with_event_logging\n    original_fn_result = original_fn(*og_args, **og_kwargs)\n                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\amros\\.conda\\envs\\whisper_test\\Lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py\", line 472, in _original_fn\n    original_result = original(*_og_args, **_og_kwargs)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\amros\\.conda\\envs\\whisper_test\\Lib\\site-packages\\crewai\\agent.py\", line 462, in execute_task\n    raise e\n  File \"C:\\Users\\amros\\.conda\\envs\\whisper_test\\Lib\\site-packages\\crewai\\agent.py\", line 438, in execute_task\n    result = self._execute_without_timeout(task_prompt, task)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\amros\\.conda\\envs\\whisper_test\\Lib\\site-packages\\crewai\\agent.py\", line 534, in _execute_without_timeout\n    return self.agent_executor.invoke(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\amros\\.conda\\envs\\whisper_test\\Lib\\site-packages\\crewai\\agents\\crew_agent_executor.py\", line 125, in invoke\n    raise e\n  File \"C:\\Users\\amros\\.conda\\envs\\whisper_test\\Lib\\site-packages\\crewai\\agents\\crew_agent_executor.py\", line 114, in invoke\n    formatted_answer = self._invoke_loop()\n                       ^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\amros\\.conda\\envs\\whisper_test\\Lib\\site-packages\\crewai\\agents\\crew_agent_executor.py\", line 211, in _invoke_loop\n    raise e\n  File \"C:\\Users\\amros\\.conda\\envs\\whisper_test\\Lib\\site-packages\\crewai\\agents\\crew_agent_executor.py\", line 157, in _invoke_loop\n    answer = get_llm_response(\n             ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\amros\\.conda\\envs\\whisper_test\\Lib\\site-packages\\crewai\\utilities\\agent_utils.py\", line 164, in get_llm_response\n    raise e\n  File \"C:\\Users\\amros\\.conda\\envs\\whisper_test\\Lib\\site-packages\\crewai\\utilities\\agent_utils.py\", line 153, in get_llm_response\n    answer = llm.call(\n             ^^^^^^^^^\n  File \"C:\\Users\\amros\\.conda\\envs\\whisper_test\\Lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py\", line 484, in safe_patch_function\n    patch_function(call_original, *args, **kwargs)\n  File \"C:\\Users\\amros\\.conda\\envs\\whisper_test\\Lib\\site-packages\\mlflow\\crewai\\autolog.py\", line 28, in patched_class_call\n    result = original(self, *args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\amros\\.conda\\envs\\whisper_test\\Lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py\", line 475, in call_original\n    return call_original_fn_with_event_logging(_original_fn, og_args, og_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\amros\\.conda\\envs\\whisper_test\\Lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py\", line 426, in call_original_fn_with_event_logging\n    original_fn_result = original_fn(*og_args, **og_kwargs)\n                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\amros\\.conda\\envs\\whisper_test\\Lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py\", line 472, in _original_fn\n    original_result = original(*_og_args, **_og_kwargs)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\amros\\.conda\\envs\\whisper_test\\Lib\\site-packages\\crewai\\llm.py\", line 977, in call\n    return self._handle_non_streaming_response(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\amros\\.conda\\envs\\whisper_test\\Lib\\site-packages\\crewai\\llm.py\", line 782, in _handle_non_streaming_response\n    response = litellm.completion(**params)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\amros\\.conda\\envs\\whisper_test\\Lib\\site-packages\\litellm\\utils.py\", line 1285, in wrapper\n    raise e\n  File \"C:\\Users\\amros\\.conda\\envs\\whisper_test\\Lib\\site-packages\\litellm\\utils.py\", line 1163, in wrapper\n    result = original_function(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\amros\\.conda\\envs\\whisper_test\\Lib\\site-packages\\litellm\\main.py\", line 3304, in completion\n    raise exception_type(\n  File \"C:\\Users\\amros\\.conda\\envs\\whisper_test\\Lib\\site-packages\\litellm\\main.py\", line 1052, in completion\n    model, custom_llm_provider, dynamic_api_key, api_base = get_llm_provider(\n                                                            ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\amros\\.conda\\envs\\whisper_test\\Lib\\site-packages\\litellm\\litellm_core_utils\\get_llm_provider_logic.py\", line 373, in get_llm_provider\n    raise e\n  File \"C:\\Users\\amros\\.conda\\envs\\whisper_test\\Lib\\site-packages\\litellm\\litellm_core_utils\\get_llm_provider_logic.py\", line 350, in get_llm_provider\n    raise litellm.exceptions.BadRequestError(  # type: ignore\nlitellm.exceptions.BadRequestError: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=models/gemini-pro\n Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers\n", "exception.escaped": "False"}}], "status": {"message": "BadRequestError: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=models/gemini-pro\n Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers", "code": "STATUS_CODE_ERROR"}}, {"trace_id": "yHRvTpkmri8eIfgbBdTbdw==", "span_id": "HWu8eVs10DA=", "trace_state": "", "parent_span_id": "4mWmhjwyZXk=", "name": "Agent.execute_task", "start_time_unix_nano": 1753087328110691100, "end_time_unix_nano": 1753087328235250600, "attributes": {"crew": "\"parent_flow=None name=None cache=True tasks=[Task(description=Manage the process of analyzing a transcript segment for compliance violations. First, delegate the analysis of the segment: \\\"انا عرضت data العملاء علي اخويا وهو قالي كدا\\\" to the compliance_analyst. Then, delegate the creation of a final report to the compliance_reporter based on the analysis. Finally, review the report for accuracy and completeness before finishing the task.\\n, expected_output=The final, verified compliance report.\\n), Task(description=Analyze the following transcript segment for any potential compliance violations based on the provided knowledge base: انا عرضت data العملاء علي اخويا وهو قالي كدا. Focus on identifying specific phrases or statements that might indicate a breach of policy or regulation.\\n, expected_output=A list of potential compliance violations found in the text, with a brief explanation for each. If no violations are found, state that clearly.\\n), Task(description=Review the analysis of the transcript segment and create a comprehensive compliance report. The report should summarize the findings, detail any violations, and suggest a risk level.\\n, expected_output=A well-structured compliance report in markdown format. It should include an executive summary, a list of findings, and a final compliance assessment.\\n)] agents=[Agent(role=Compliance Manager, goal=Oversee the compliance analysis and reporting process. Ensure the final report is accurate, complete, and addresses all potential risks identified in the transcript segment by delegating tasks to the analyst and reporter.\\n, backstory=You are an experienced compliance manager with a keen eye for detail and a talent for coordinating team efforts. Your primary responsibility is to ensure that all compliance checks are thorough and that the final reports are clear, concise, and actionable.\\n), Agent(role=Compliance Analyst, goal=Perform comprehensive compliance analysis of input phrases using intelligent screening.\\nPHASE 1 - PRELIMINARY JUDGMENT: Use your expertise to quickly assess if the phrase is: - Obviously safe routine business communication (greetings, project updates, scheduling) - Clearly irrelevant to compliance concerns - Standard workplace conversation with no red flags\\nIf obviously safe, immediately respond with \\\"SAFE - No compliance concerns detected\\\" and provide brief reasoning.\\nPHASE 2 - DETAILED ANALYSIS: Only if the phrase contains potential risks, ambiguous content, or compliance-relevant keywords: - Search the knowledge base (data.json) for specific regulatory matches - Apply built-in compliance intelligence for violation detection - Analyze against regulatory frameworks (SEC, GDPR, FCPA, SOX, OSHA, etc.) - Evaluate policy violations and risk factors\\nIf knowledge base search yields no results, apply your expertise to determine if genuine violations exist. Provide detailed analysis findings including violation types, regulatory frameworks, risk levels, and evidence.\\n, backstory=You are a senior compliance analyst with deep expertise in regulatory frameworks, corporate policies,  and violation detection. You excel at quickly distinguishing between routine business communication  and genuine compliance risks. You rely on documented knowledge when available, but can apply your  extensive experience when knowledge bases are incomplete. You prioritize accuracy over false alarms  and provide thorough analysis only when warranted.\\n), Agent(role=Compliance Reporter, goal=Generate executive-level compliance reports based on the compliance_analyst's findings.\\nCreate final compliance determinations with clear, actionable guidance:\\nFOR SAFE DETERMINATIONS: - Confirm the safety classification with confidence level - Document the analysis method used (preliminary screening vs. full analysis) - Provide brief executive summary - Set appropriate monitoring level (routine/standard)\\nFOR VIOLATION DETERMINATIONS: - Detail specific compliance violations and regulatory concerns - List applicable regulatory frameworks and policy breaches - Classify risk severity and urgency level - Outline required immediate actions and escalation procedures - Specify responsible parties and follow-up requirements - Determine alert level and notification protocols\\nAlways provide clear final verdicts: SAFE or VIOLATION Include confidence levels, risk classifications, and actionable next steps. Ensure executives can make informed decisions based on your reports.\\n, backstory=You are an experienced compliance reporting specialist who translates technical compliance  analysis into clear, actionable executive guidance. You excel at synthesizing complex  regulatory findings into concise reports that enable quick decision-making. You understand  business impact, escalation requirements, and risk management. Your reports are trusted  by senior management for their accuracy, clarity, and practical recommendations. You ensure  appropriate responses to both genuine violations and false alarms.\\n)] process=<Process.hierarchical: 'hierarchical'> verbose=True memory=False memory_config=None short_term_memory=None long_term_memory=None entity_memory=None user_memory=None external_memory=None embedder=None usage_metrics=None manager_llm=<crewai.llm.LLM object at 0x000001C8C2267E50> manager_agent=Agent(role=Crew Manager, goal=Manage the team to complete the task in the best way possible., backstory=You are a seasoned manager with a knack for getting the best out of your team.\\nYou are also known for your ability to delegate work to the right people, and to ask the right questions to get the best out of your team.\\nEven though you don't perform tasks by yourself, you have a lot of experience in the field, which allows you to properly evaluate the work of your team members.) function_calling_llm=None config=None id=UUID('dea95942-8c1c-435b-8648-6492c96c4128') share_crew=False step_callback=None task_callback=None before_kickoff_callbacks=[] after_kickoff_callbacks=[<function crew.<locals>.wrapper.<locals>.callback_wrapper.<locals>.wrapper at 0x000001C8C2258220>] max_rpm=None prompt_file=None output_log_file=None planning=False planning_llm=None task_execution_output_json_files=None execution_logs=[] knowledge_sources=None chat_llm=None knowledge=None security_config=SecurityConfig(version='1.0.0', fingerprint=Fingerprint(uuid_str='cd53c3a3-9bc1-41eb-b6f8-63cf2d6a8b47', created_at=datetime.datetime(2025, 7, 21, 11, 42, 7, 719805), metadata={}))\"", "date_format": "\"%Y-%m-%d\"", "tools_handler": "\"<crewai.agents.tools_handler.ToolsHandler object at 0x000001C8B24526D0>\"", "cache": "\"True\"", "adapted_agent": "\"False\"", "use_system_prompt": "\"True\"", "tools": "\"[{'type': 'function', 'function': {'name': 'Delegate work to coworker', 'description': \\\"Tool Name: Delegate work to coworker\\\\nTool Arguments: {'task': {'description': 'The task to delegate', 'type': 'str'}, 'context': {'description': 'The context for the task', 'type': 'str'}, 'coworker': {'description': 'The role/name of the coworker to delegate to', 'type': 'str'}}\\\\nTool Description: Delegate a specific task to one of the following coworkers: Compliance Manager, Compliance Analyst, Compliance Reporter\\\\nThe input to this tool should be the coworker, the task you want them to do, and ALL necessary context to execute the task, they know nothing about the task, so share absolutely everything you know, don't reference things but instead explain them.\\\"}}, {'type': 'function', 'function': {'name': 'Ask question to coworker', 'description': \\\"Tool Name: Ask question to coworker\\\\nTool Arguments: {'question': {'description': 'The question to ask', 'type': 'str'}, 'context': {'description': 'The context for the question', 'type': 'str'}, 'coworker': {'description': 'The role/name of the coworker to ask', 'type': 'str'}}\\\\nTool Description: Ask a specific question to one of the following coworkers: Compliance Manager, Compliance Analyst, Compliance Reporter\\\\nThe input to this tool should be the coworker, the question you have for them, and ALL necessary context to ask the question properly, they know nothing about the question, so share absolutely everything you know, don't reference things but instead explain them.\\\"}}]\"", "mlflow.traceRequestId": "\"97044c291e204ebd91f62b49e2dc0cd8\"", "mlflow.spanType": "\"AGENT\"", "llm": "\"<crewai.llm.LLM object at 0x000001C8C2267E50>\"", "agent_executor": "\"<crewai.agents.crew_agent_executor.CrewAgentExecutor object at 0x000001C8C2900490>\"", "code_execution_mode": "\"safe\"", "i18n": "\"prompt_file=None\"", "max_iter": "\"25\"", "cache_handler": "\"\"", "tools_results": "\"[]\"", "agent_ops_agent_name": "\"Crew Manager\"", "id": "\"c7ea0466-5a21-443d-a0e3-00f584e3196f\"", "verbose": "\"True\"", "goal": "\"Manage the team to complete the task in the best way possible.\"", "respect_context_window": "\"True\"", "security_config": "\"version='1.0.0' fingerprint=Fingerprint(uuid_str='33cd6353-46f7-449a-a621-b74f912ebc17', created_at=datetime.datetime(2025, 7, 21, 11, 42, 8, 90186), metadata={})\"", "backstory": "\"You are a seasoned manager with a knack for getting the best out of your team.\\nYou are also known for your ability to delegate work to the right people, and to ask the right questions to get the best out of your team.\\nEven though you don't perform tasks by yourself, you have a lot of experience in the field, which allows you to properly evaluate the work of your team members.\"", "allow_delegation": "\"True\"", "role": "\"Crew Manager\"", "callbacks": "\"[]\"", "multimodal": "\"False\"", "mlflow.spanInputs": "{\"context\": \"\"}", "reasoning": "\"False\"", "max_retry_limit": "\"2\"", "allow_code_execution": "\"False\"", "guardrail_max_retries": "\"3\"", "inject_date": "\"False\""}, "events": [{"time_unix_nano": 1753087328235250600, "name": "exception", "attributes": {"exception.type": "litellm.exceptions.BadRequestError", "exception.message": "litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=models/gemini-pro\n Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers", "exception.stacktrace": "Traceback (most recent call last):\n  File \"C:\\Users\\amros\\.conda\\envs\\whisper_test\\Lib\\site-packages\\opentelemetry\\trace\\__init__.py\", line 589, in use_span\n    yield span\n  File \"C:\\Users\\amros\\.conda\\envs\\whisper_test\\Lib\\site-packages\\mlflow\\tracing\\fluent.py\", line 478, in start_span\n    yield mlflow_span\n  File \"C:\\Users\\amros\\.conda\\envs\\whisper_test\\Lib\\site-packages\\mlflow\\crewai\\autolog.py\", line 28, in patched_class_call\n    result = original(self, *args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\amros\\.conda\\envs\\whisper_test\\Lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py\", line 475, in call_original\n    return call_original_fn_with_event_logging(_original_fn, og_args, og_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\amros\\.conda\\envs\\whisper_test\\Lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py\", line 426, in call_original_fn_with_event_logging\n    original_fn_result = original_fn(*og_args, **og_kwargs)\n                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\amros\\.conda\\envs\\whisper_test\\Lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py\", line 472, in _original_fn\n    original_result = original(*_og_args, **_og_kwargs)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\amros\\.conda\\envs\\whisper_test\\Lib\\site-packages\\crewai\\agent.py\", line 462, in execute_task\n    raise e\n  File \"C:\\Users\\amros\\.conda\\envs\\whisper_test\\Lib\\site-packages\\crewai\\agent.py\", line 438, in execute_task\n    result = self._execute_without_timeout(task_prompt, task)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\amros\\.conda\\envs\\whisper_test\\Lib\\site-packages\\crewai\\agent.py\", line 534, in _execute_without_timeout\n    return self.agent_executor.invoke(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\amros\\.conda\\envs\\whisper_test\\Lib\\site-packages\\crewai\\agents\\crew_agent_executor.py\", line 125, in invoke\n    raise e\n  File \"C:\\Users\\amros\\.conda\\envs\\whisper_test\\Lib\\site-packages\\crewai\\agents\\crew_agent_executor.py\", line 114, in invoke\n    formatted_answer = self._invoke_loop()\n                       ^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\amros\\.conda\\envs\\whisper_test\\Lib\\site-packages\\crewai\\agents\\crew_agent_executor.py\", line 211, in _invoke_loop\n    raise e\n  File \"C:\\Users\\amros\\.conda\\envs\\whisper_test\\Lib\\site-packages\\crewai\\agents\\crew_agent_executor.py\", line 157, in _invoke_loop\n    answer = get_llm_response(\n             ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\amros\\.conda\\envs\\whisper_test\\Lib\\site-packages\\crewai\\utilities\\agent_utils.py\", line 164, in get_llm_response\n    raise e\n  File \"C:\\Users\\amros\\.conda\\envs\\whisper_test\\Lib\\site-packages\\crewai\\utilities\\agent_utils.py\", line 153, in get_llm_response\n    answer = llm.call(\n             ^^^^^^^^^\n  File \"C:\\Users\\amros\\.conda\\envs\\whisper_test\\Lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py\", line 484, in safe_patch_function\n    patch_function(call_original, *args, **kwargs)\n  File \"C:\\Users\\amros\\.conda\\envs\\whisper_test\\Lib\\site-packages\\mlflow\\crewai\\autolog.py\", line 28, in patched_class_call\n    result = original(self, *args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\amros\\.conda\\envs\\whisper_test\\Lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py\", line 475, in call_original\n    return call_original_fn_with_event_logging(_original_fn, og_args, og_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\amros\\.conda\\envs\\whisper_test\\Lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py\", line 426, in call_original_fn_with_event_logging\n    original_fn_result = original_fn(*og_args, **og_kwargs)\n                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\amros\\.conda\\envs\\whisper_test\\Lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py\", line 472, in _original_fn\n    original_result = original(*_og_args, **_og_kwargs)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\amros\\.conda\\envs\\whisper_test\\Lib\\site-packages\\crewai\\llm.py\", line 977, in call\n    return self._handle_non_streaming_response(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\amros\\.conda\\envs\\whisper_test\\Lib\\site-packages\\crewai\\llm.py\", line 782, in _handle_non_streaming_response\n    response = litellm.completion(**params)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\amros\\.conda\\envs\\whisper_test\\Lib\\site-packages\\litellm\\utils.py\", line 1285, in wrapper\n    raise e\n  File \"C:\\Users\\amros\\.conda\\envs\\whisper_test\\Lib\\site-packages\\litellm\\utils.py\", line 1163, in wrapper\n    result = original_function(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\amros\\.conda\\envs\\whisper_test\\Lib\\site-packages\\litellm\\main.py\", line 3304, in completion\n    raise exception_type(\n  File \"C:\\Users\\amros\\.conda\\envs\\whisper_test\\Lib\\site-packages\\litellm\\main.py\", line 1052, in completion\n    model, custom_llm_provider, dynamic_api_key, api_base = get_llm_provider(\n                                                            ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\amros\\.conda\\envs\\whisper_test\\Lib\\site-packages\\litellm\\litellm_core_utils\\get_llm_provider_logic.py\", line 373, in get_llm_provider\n    raise e\n  File \"C:\\Users\\amros\\.conda\\envs\\whisper_test\\Lib\\site-packages\\litellm\\litellm_core_utils\\get_llm_provider_logic.py\", line 350, in get_llm_provider\n    raise litellm.exceptions.BadRequestError(  # type: ignore\nlitellm.exceptions.BadRequestError: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=models/gemini-pro\n Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers\n", "exception.escaped": "False"}}], "status": {"message": "BadRequestError: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=models/gemini-pro\n Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers", "code": "STATUS_CODE_ERROR"}}, {"trace_id": "yHRvTpkmri8eIfgbBdTbdw==", "span_id": "MaeQ//oSQFU=", "trace_state": "", "parent_span_id": "HWu8eVs10DA=", "name": "LLM.call", "start_time_unix_nano": 1753087328135474100, "end_time_unix_nano": 1753087328229218100, "attributes": {"stop": "\"['\\\\nObservation:']\"", "mlflow.traceRequestId": "\"97044c291e204ebd91f62b49e2dc0cd8\"", "additional_params": "\"{}\"", "model": "\"models/gemini-pro\"", "mlflow.spanType": "\"LLM\"", "mlflow.spanInputs": "{\"messages\": [{\"role\": \"system\", \"content\": \"You are Crew Manager. You are a seasoned manager with a knack for getting the best out of your team.\\nYou are also known for your ability to delegate work to the right people, and to ask the right questions to get the best out of your team.\\nEven though you don't perform tasks by yourself, you have a lot of experience in the field, which allows you to properly evaluate the work of your team members.\\nYour personal goal is: Manage the team to complete the task in the best way possible.\\nYou ONLY have access to the following tools, and should NEVER make up tools that are not listed here:\\n\\nTool Name: Delegate work to coworker\\nTool Arguments: {'task': {'description': 'The task to delegate', 'type': 'str'}, 'context': {'description': 'The context for the task', 'type': 'str'}, 'coworker': {'description': 'The role/name of the coworker to delegate to', 'type': 'str'}}\\nTool Description: Delegate a specific task to one of the following coworkers: Compliance Manager\\nThe input to this tool should be the coworker, the task you want them to do, and ALL necessary context to execute the task, they know nothing about the task, so share absolutely everything you know, don't reference things but instead explain them.\\nTool Name: Ask question to coworker\\nTool Arguments: {'question': {'description': 'The question to ask', 'type': 'str'}, 'context': {'description': 'The context for the question', 'type': 'str'}, 'coworker': {'description': 'The role/name of the coworker to ask', 'type': 'str'}}\\nTool Description: Ask a specific question to one of the following coworkers: Compliance Manager\\nThe input to this tool should be the coworker, the question you have for them, and ALL necessary context to ask the question properly, they know nothing about the question, so share absolutely everything you know, don't reference things but instead explain them.\\n\\nIMPORTANT: Use the following format in your response:\\n\\n```\\nThought: you should always think about what to do\\nAction: the action to take, only one name of [Delegate work to coworker, Ask question to coworker], just the name, exactly as it's written.\\nAction Input: the input to the action, just a simple JSON object, enclosed in curly braces, using \\\" to wrap keys and values.\\nObservation: the result of the action\\n```\\n\\nOnce all necessary information is gathered, return the following format:\\n\\n```\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n```\"}, {\"role\": \"user\", \"content\": \"\\nCurrent Task: Manage the process of analyzing a transcript segment for compliance violations. First, delegate the analysis of the segment: \\\"انا عرضت data العملاء علي اخويا وهو قالي كدا\\\" to the compliance_analyst. Then, delegate the creation of a final report to the compliance_reporter based on the analysis. Finally, review the report for accuracy and completeness before finishing the task.\\n\\n\\nThis is the expected criteria for your final answer: The final, verified compliance report.\\n\\nyou MUST return the actual complete content as the final answer, not a summary.\\n\\nBegin! This is VERY important to you, use the tools available and give your best Final Answer, your job depends on it!\\n\\nThought:\"}], \"callbacks\": [\"<crewai.utilities.token_counter_callback.TokenCalcHandler object at 0x000001C8C2B402D0>\"]}", "temperature": "\"0.7\"", "is_anthropic": "\"False\"", "context_window_size": "\"0\"", "stream": "\"False\""}, "events": [{"time_unix_nano": 1753087328229218100, "name": "exception", "attributes": {"exception.type": "litellm.exceptions.BadRequestError", "exception.message": "litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=models/gemini-pro\n Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers", "exception.stacktrace": "Traceback (most recent call last):\n  File \"C:\\Users\\amros\\.conda\\envs\\whisper_test\\Lib\\site-packages\\opentelemetry\\trace\\__init__.py\", line 589, in use_span\n    yield span\n  File \"C:\\Users\\amros\\.conda\\envs\\whisper_test\\Lib\\site-packages\\mlflow\\tracing\\fluent.py\", line 478, in start_span\n    yield mlflow_span\n  File \"C:\\Users\\amros\\.conda\\envs\\whisper_test\\Lib\\site-packages\\mlflow\\crewai\\autolog.py\", line 28, in patched_class_call\n    result = original(self, *args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\amros\\.conda\\envs\\whisper_test\\Lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py\", line 475, in call_original\n    return call_original_fn_with_event_logging(_original_fn, og_args, og_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\amros\\.conda\\envs\\whisper_test\\Lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py\", line 426, in call_original_fn_with_event_logging\n    original_fn_result = original_fn(*og_args, **og_kwargs)\n                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\amros\\.conda\\envs\\whisper_test\\Lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py\", line 472, in _original_fn\n    original_result = original(*_og_args, **_og_kwargs)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\amros\\.conda\\envs\\whisper_test\\Lib\\site-packages\\crewai\\llm.py\", line 977, in call\n    return self._handle_non_streaming_response(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\amros\\.conda\\envs\\whisper_test\\Lib\\site-packages\\crewai\\llm.py\", line 782, in _handle_non_streaming_response\n    response = litellm.completion(**params)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\amros\\.conda\\envs\\whisper_test\\Lib\\site-packages\\litellm\\utils.py\", line 1285, in wrapper\n    raise e\n  File \"C:\\Users\\amros\\.conda\\envs\\whisper_test\\Lib\\site-packages\\litellm\\utils.py\", line 1163, in wrapper\n    result = original_function(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\amros\\.conda\\envs\\whisper_test\\Lib\\site-packages\\litellm\\main.py\", line 3304, in completion\n    raise exception_type(\n  File \"C:\\Users\\amros\\.conda\\envs\\whisper_test\\Lib\\site-packages\\litellm\\main.py\", line 1052, in completion\n    model, custom_llm_provider, dynamic_api_key, api_base = get_llm_provider(\n                                                            ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\amros\\.conda\\envs\\whisper_test\\Lib\\site-packages\\litellm\\litellm_core_utils\\get_llm_provider_logic.py\", line 373, in get_llm_provider\n    raise e\n  File \"C:\\Users\\amros\\.conda\\envs\\whisper_test\\Lib\\site-packages\\litellm\\litellm_core_utils\\get_llm_provider_logic.py\", line 350, in get_llm_provider\n    raise litellm.exceptions.BadRequestError(  # type: ignore\nlitellm.exceptions.BadRequestError: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=models/gemini-pro\n Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers\n", "exception.escaped": "False"}}], "status": {"message": "BadRequestError: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=models/gemini-pro\n Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers", "code": "STATUS_CODE_ERROR"}}]}